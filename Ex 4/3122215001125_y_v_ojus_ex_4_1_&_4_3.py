# -*- coding: utf-8 -*-
"""3122215001125_Y.V.Ojus_Ex 4.1 & 4.3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y6s-LNbCCJAekVY-aowbxfK3nDtYDELn

## Clone GitHub Repo For Data
"""

!git clone https://github.com/Ojus999/Machine-Learning-Sem-6.git

"""## Import Dependencies"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn import svm

"""## Read Data"""

df = pd.read_csv("/content/Machine-Learning-Sem-6/Ex 4/spambase_csv.csv")

"""## Read First Few Rows"""

df.head()

"""## DataFrame Info"""

df.info()

"""## Data Visualization

### Data Distribution
"""

class_counts = df['class'].value_counts()
plt.bar(class_counts.index, class_counts.values)
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Distribution of Email Classes')
plt.xticks(class_counts.index, ['Non-Spam', 'Spam'])
plt.show()

"""### Correlation Heatmap

"""

correlation_matrix = df.corr()

# Create a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

"""## Histograms & Boxplot"""

df.columns

word_freq_columns = df.loc[:, 'word_freq_make':'word_freq_conference'].columns
index = 1


# Plot boxplots for word frequency features
plt.figure(figsize=(12, 8))
sns.boxplot(data=df[word_freq_columns[index]])
plt.xlabel('Word Frequency Features')
plt.ylabel('Frequency')
plt.title(f'Boxplot of {word_freq_columns[index]} Features')
plt.xticks(rotation=45)
plt.show()

word_freq_columns = df.loc[:, 'word_freq_make':'word_freq_conference'].columns
index = 0

# Plot histogram for the selected word frequency feature
plt.figure(figsize=(12, 8))
sns.histplot(data=df[word_freq_columns[index]], bins=20)  # Adjust bins and kde as needed
plt.xlabel('Word Frequency')
plt.ylabel('Frequency')
plt.title(f'Histogram of {word_freq_columns[index]} Features')
plt.xticks(rotation=45)
plt.show()

"""## Null Values"""

df.isnull().sum()

"""## Statistics Of Data"""

df.describe().transpose()

"""# Building Model - SVM

### Define Train And Target Columns
"""

X = df.loc[:,'word_freq_make':'capital_run_length_total']
X

y = df['class']

"""### Train Test Split"""

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=109)

"""### Perform Feature Scaling - Standardization"""

# Feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""### Fit And Predict"""

kernels = ['linear','poly','rbf','sigmoid']

for ker in kernels:
  #Create a svm Classifier
  clf = svm.SVC(kernel=ker) # Linear Kernel

  #Train the model using the training sets
  clf.fit(X_train, y_train)

  #Predict the response for test dataset
  y_pred = clf.predict(X_test)

  # Model Accuracy: how often is the classifier correct?
  accuracy = metrics.accuracy_score(y_test, y_pred)
  print(f"Kernel: {ker}")
  print("Accuracy:", accuracy)

  # Model Precision: what percentage of positive tuples are labeled as such?
  precision = metrics.precision_score(y_test, y_pred)
  print("Precision:", precision)

  # Model Recall: what percentage of positive tuples are labelled as such?
  recall = metrics.recall_score(y_test, y_pred)
  print("Recall:", recall)

  print()

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

"""## Accuracy"""

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""### Precision & Recall"""

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

"""## Visualize Output

### Classification Report
"""

# Classification Report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""### Confusion Matrix"""

# Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
cm_display = metrics.ConfusionMatrixDisplay(cm)
cm_display.plot()

"""# Building Model - Naive Bayes

### Train Test Split
"""

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=109)

"""### Feature Scaling"""

# Feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""### Initialize Model"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()

"""### Fit And Predict"""

y_pred = gnb.fit(X_train, y_train).predict(X_test)

"""### Accuracy"""

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""### Precision & Recall"""

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

"""## Visualizing Output

### Classification Report
"""

# Classification Report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""### Confusion Matrix"""

# Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
cm_display = metrics.ConfusionMatrixDisplay(cm)
cm_display.plot()